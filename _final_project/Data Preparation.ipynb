{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e132178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5869ede3",
   "metadata": {},
   "source": [
    "Isolating work just in the Fine Arts department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be26ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cmoa.csv', 'rt', encoding = 'utf8') as inp, open('cmoa_fine_art.csv', 'wt', encoding = 'utf8') as out:\n",
    "    writer = csv.writer(out)\n",
    "    for row in csv.reader(inp):\n",
    "        if row[10] != \"Fine Arts\":\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a8f2a0",
   "metadata": {},
   "source": [
    "Mady silly mistake of using the wrong index, so I'll try to isolate Fine Arts again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d02c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cmoa.csv', 'rt', encoding = 'utf8') as inp, open('cmoa_fine_art.csv', 'wt', encoding = 'utf8') as out:\n",
    "    writer = csv.writer(out)\n",
    "    for row in csv.reader(inp):\n",
    "        if row[9] != \"Fine Arts\":\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2faadc",
   "metadata": {},
   "source": [
    "Still having issues, realized operation was incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd45e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = open('cmoa_fine_art.csv', 'wt', encoding = 'utf8')\n",
    "# writer = csv.writer(out)\n",
    "# inp = open('cmoa.csv', 'rt', encoding = 'utf8')\n",
    "# row = row in csv.reader(inp)\n",
    "# writer.writerow(row)\n",
    "\n",
    "with open('cmoa.csv', 'rt', encoding = 'utf8') as inp, open('cmoa_fine_art.csv', 'wt', encoding = 'utf8') as out:\n",
    "#     heading = next(inp)\n",
    "    writer = csv.writer(out)\n",
    "#     writer.writerow(heading)\n",
    "    for row in csv.reader(inp):\n",
    "        if row[9] == \"Fine Arts\":\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd8d7f",
   "metadata": {},
   "source": [
    "At a glance, it seems like each row has an arbitrary row of whitespace separating each of the rows that have information, so I'll attempt to remove those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "306abe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cmoa_fine_art.csv')\n",
    "df.to_csv('cmoa_fine_art1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f9198",
   "metadata": {},
   "source": [
    "I also need to remove any \"Notes\" since they may cause issues in the csv file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "606025d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minni\\AppData\\Local\\Temp\\ipykernel_33888\\1268749144.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv('cmoa_fine_art1.csv', error_bad_lines = False).dropna()\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('cmoa_fine_art1.csv', error_bad_lines = False).dropna()\n",
    "df.to_csv('cmoa_fine_art2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de816fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cmoa_fine_art1.csv', 'rt', encoding = 'utf8') as inp, open('cmoa_fine_art2.csv', 'wt', encoding = 'utf8') as out:\n",
    "    writer = csv.writer(out)\n",
    "    for row in csv.reader(inp):\n",
    "        if row[0] != \"Notes:\" and row[0][0] != '[':\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8eb3c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('cmoa_fine_art.csv', 'rt', encoding = 'utf8') as inp, open('cmoa_fine_art_1.csv', 'wt', encoding = 'utf8') as out:\n",
    "#     writer = csv.writer(out)\n",
    "#     for row in csv.reader(inp):\n",
    "#         if row != \"\\n\":\n",
    "#             writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b3e181",
   "metadata": {},
   "source": [
    "After attempting to also copy over the header of the csv file, I realized it would be quicker to simploy copy and paste it manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb255b",
   "metadata": {},
   "source": [
    "Let's also remove all the rows that do not include a nationality, which is at index 24. Alternatively, we can reference that information with the \"nationality\" key word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1af0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = df[\"nationality\"] != \"\"\n",
    "df_clean = df[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c9bca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cmoa_fine_art3.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9886a071",
   "metadata": {},
   "source": [
    "Let's compare the lengths of the csv files to see if any changes were made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "058b14ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('cmoa.csv')\n",
    "results0 = pd.read_csv('cmoa_fine_art.csv')\n",
    "results1 = pd.read_csv('cmoa_fine_art1.csv')\n",
    "results2 = pd.read_csv('cmoa_fine_art2.csv')\n",
    "results3 = pd.read_csv('cmoa_fine_art3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95eb645f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28269\n",
      "8972\n",
      "8972\n",
      "1177\n",
      "1177\n"
     ]
    }
   ],
   "source": [
    "print(len(original))\n",
    "print(len(results0))\n",
    "print(len(results1))\n",
    "print(len(results2))\n",
    "print(len(results3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49adacc9",
   "metadata": {},
   "source": [
    "While some of the cleaning may have been done incorrectly or may have been repetative, the resulting 1177 rows is now much more usable than the original 28269 for this project-- 4.16% of the number of pieces we began with!\n",
    "\n",
    "The largest change was when I reduced the scope from the entire collection to the Fine Arts department. This superficially showcases the proportion of work in the CMOA that is considered as Fine Art (although what can be defined as such is an entirely separate discussion). Interestingly enough, in this dataset, Contemporary Art is labelled as a separate department. I can therefore infer that the work in the Fine Arts department is somewhat historical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cada1900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                Japanese|Japanese\n",
       "1                Japanese|Japanese\n",
       "2                Japanese|Japanese\n",
       "3                   French|Italian\n",
       "4       Japanese|Japanese|Japanese\n",
       "                   ...            \n",
       "1172             American|American\n",
       "1173             American|American\n",
       "1174             American|American\n",
       "1175             Japanese|Japanese\n",
       "1176             Japanese|Japanese\n",
       "Name: nationality, Length: 1177, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cmoa_fine_art3.csv\")\n",
    "df.loc[:, \"nationality\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb7f5e",
   "metadata": {},
   "source": [
    "Below, I'm printing out specific information to get a glance at how usable the information is in order to narrow down what I include in my hosted feature layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50624d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    |\n",
       "1                    |\n",
       "2                    |\n",
       "3       |Paris, France\n",
       "4                   ||\n",
       "             ...      \n",
       "1172                 |\n",
       "1173                 |\n",
       "1174                 |\n",
       "1175                 |\n",
       "1176                 |\n",
       "Name: death_place, Length: 1177, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, \"death_place\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f7077b",
   "metadata": {},
   "source": [
    "I'm going to try to input the nationality data into ArcGIS to see if it can recognize the phrasing as a location. If not, I will need to continue to process the data to convert the nationality to a location. If all ese fails, I may need to use alternative methods to visualize this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e65e044f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Not on View\n",
       "1       Not on View\n",
       "2       Not on View\n",
       "3       Not on View\n",
       "4       Not on View\n",
       "           ...     \n",
       "1172    Not on View\n",
       "1173    Not on View\n",
       "1174    Not on View\n",
       "1175    Not on View\n",
       "1176    Not on View\n",
       "Name: physical_location, Length: 1177, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, \"physical_location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d1b9a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       prints\n",
       "1       prints\n",
       "2       prints\n",
       "3       prints\n",
       "4        books\n",
       "         ...  \n",
       "1172    prints\n",
       "1173    prints\n",
       "1174    prints\n",
       "1175    prints\n",
       "1176    prints\n",
       "Name: classification, Length: 1177, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, \"classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "707a157a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Person|Person\n",
       "1              Person|Person\n",
       "2              Person|Person\n",
       "3              Person|Person\n",
       "4       Person|Person|Person\n",
       "                ...         \n",
       "1172           Person|Person\n",
       "1173           Person|Person\n",
       "1174           Person|Person\n",
       "1175           Person|Person\n",
       "1176           Person|Person\n",
       "Name: party_type, Length: 1177, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, \"party_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "041b2eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       cmoa:parties/e5115fa9-4d3b-4ce1-b4ab-665937b0f...\n",
       "1       cmoa:parties/e5115fa9-4d3b-4ce1-b4ab-665937b0f...\n",
       "2       cmoa:parties/e5115fa9-4d3b-4ce1-b4ab-665937b0f...\n",
       "3       cmoa:parties/eccddfd9-40ae-4159-bfa4-8cb397ff8...\n",
       "4       cmoa:parties/3f8d5656-1fd7-4a8e-91ff-6e8987877...\n",
       "                              ...                        \n",
       "1172    cmoa:parties/ba8c351a-1864-4867-bb31-c85ef426b...\n",
       "1173    cmoa:parties/ba8c351a-1864-4867-bb31-c85ef426b...\n",
       "1174    cmoa:parties/ba8c351a-1864-4867-bb31-c85ef426b...\n",
       "1175    cmoa:parties/4920283a-25c2-49b6-97df-2a8e6e4d7...\n",
       "1176    cmoa:parties/4920283a-25c2-49b6-97df-2a8e6e4d7...\n",
       "Name: artist_id, Length: 1177, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, \"artist_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "904f3ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           artist|publisher\n",
       "1           artist|publisher\n",
       "2           artist|publisher\n",
       "3                     after|\n",
       "4       publisher|publisher|\n",
       "                ...         \n",
       "1172                       |\n",
       "1173                       |\n",
       "1174                       |\n",
       "1175                       |\n",
       "1176    Printmaker|publisher\n",
       "Name: role, Length: 1177, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, \"role\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ff8ea95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Bequest of Dr. James B. Austin, Pittsburgh, PA...\n",
       "1       Bequest of Dr. James B. Austin, Pittsburgh, PA...\n",
       "2       Bequest of Dr. James B. Austin, Pittsburgh, PA...\n",
       "3       Dukes of Marlborough and Northumberland, Syon ...\n",
       "4       Bequest of Dr. James B. Austin, Pittsburgh, PA...\n",
       "                              ...                        \n",
       "1172    Earl Purdy [1892-1971]. David L. Purdy, Pittsb...\n",
       "1173    Earl Purdy [1892-1971]. David L. Purdy, Pittsb...\n",
       "1174    Earl Purdy [1892-1971]. David L. Purdy, Pittsb...\n",
       "1175                       Charles Husted, Pittsburgh, PA\n",
       "1176                       Charles Husted, Pittsburgh, PA\n",
       "Name: provenance_text, Length: 1177, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, \"provenance_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f8db350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1929-05-18\n",
       "1       1929-07-30\n",
       "2       1929-01-01\n",
       "3       1544-12-22\n",
       "4       1715-01-01\n",
       "           ...    \n",
       "1172    1930-01-01\n",
       "1173    1952-01-01\n",
       "1174    1952-01-01\n",
       "1175    1940-01-01\n",
       "1176    1941-01-01\n",
       "Name: creation_date_earliest, Length: 1177, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, \"creation_date_earliest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c002083c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          5/18/1929\n",
       "1          7/30/1929\n",
       "2               1929\n",
       "3            c. 1550\n",
       "4               1715\n",
       "            ...     \n",
       "1172            1930\n",
       "1173    c. 1926-1940\n",
       "1174    c. 1926-1940\n",
       "1175            1940\n",
       "1176            1941\n",
       "Name: creation_date, Length: 1177, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, \"creation_date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6f7dad",
   "metadata": {},
   "source": [
    "While ArcGIS was able to recognize more locations this time around, it still struggled to handle multiple nationalities, and misinterpreted many as incorrect locations. This means I need to either continue cleaning the naitonalities data, or use an alternative data point such as the birth location.\n",
    "\n",
    "Let's do a quick test on ArcGIS using the birth location instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147d283f",
   "metadata": {},
   "source": [
    "Note: ArcGIS didn't allow me to use the same file for two different hosted feature layers, so I had to maek a copy of the csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ab6004",
   "metadata": {},
   "source": [
    "ArcGIS handleded the birth_place information much better, and only struggled to match up Tokyo. Since there weren't many unmatched plots, I went ahead and matched those manually. After this process, 221 of the 1176 works remained unmatched. In my cleaning process, since I didn't focus on birth_place, I didn't remove the values that had null or blank fiends for the birth_place. The remainig 221 works did not have birth_place information, so for the sake of this assignment they will be left out."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
