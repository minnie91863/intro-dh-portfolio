{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Chronicling America Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csv\n",
    "df = pd.read_csv('../data/socalism1945-1963.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change date to date-time object\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column with just year\n",
    "df['year'] = df['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate columns for analysis\n",
    "small_df = df[['year', 'lemmas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the dataframe by year and join lemmas\n",
    "grouped = small_df.groupby('year')['lemmas'].apply(','.join).reset_index()\n",
    "print(grouped.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data for sklearn\n",
    "years_list = []\n",
    "lemmas_list = []\n",
    "for index, row in grouped.iterrows():\n",
    "    years_list.append(str(row['year']))  # make the year a string\n",
    "    lemmas_list.append(row['lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tf-idf model\n",
    "vectorizer = TfidfVectorizer(max_df=.65, min_df=1, stop_words=None, \n",
    "                             use_idf= True, norm=None)\n",
    "transformed_lemmas = vectorizer.fit_transform(lemmas_list)\n",
    "transformed_lemmas_as_array = transformed_lemmas.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize results\n",
    "key_terms_by_year = {}\n",
    "for lemmas, year in zip(transformed_lemmas_as_array, years_list):\n",
    "    tf_idf_tuples = list(zip(vectorizer.get_feature_names(), lemmas))\n",
    "    sorted_tf_idf_tuples = sorted(tf_idf_tuples, key= lambda x: x[1], reverse=True)\n",
    "    k = year\n",
    "    v = sorted_tf_idf_tuples[:10]  # only getting the top ten\n",
    "    key_terms_by_year[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispaly results\n",
    "for k, v in key_terms_by_year.items():\n",
    "    result = k + ' => ' + v[0][0] + ', ' + v[1][0] + ', ' + v[2][0] + ', ' + v[3][0] + ', ' + v[4][0] + ', ' + v[5][0]+ ', ' + v[6][0] + ', ' + v[7][0] + ', ' + v[8][0] + ', ' + v[9][0]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data \n",
    "terms_by_year = {}\n",
    "for year, terms in zip(years_list, lemmas_list):\n",
    "    terms_list = terms.split(' ')\n",
    "    terms_by_year[year] = terms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional frequency distribution\n",
    "# Note: I adapted these lines of code from the NLTK\n",
    "key_words = ['proletariat', 'bourgeois']  # <-- instert token(s) to explore (lowercase)\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (key_word, year)\n",
    "    for year in terms_by_year.keys()\n",
    "    for lemma in terms_by_year[year]\n",
    "    for key_word in key_words\n",
    "    if lemma.lower() == key_word\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display plot\n",
    "plt.figure(figsize=(20, 8))  # this expands the plot to make it more readable\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
